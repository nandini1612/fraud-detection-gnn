{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfcacce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING ELLIPTIC DATASET\n",
      "================================================================================\n",
      "Loading Elliptic dataset...\n",
      "‚úì Features: (203769, 167) (nodes x features)\n",
      "‚úì Edges: (234355, 2)\n",
      "‚úì Classes: (203769, 2)\n",
      "\n",
      "‚úì Data loaded successfully!\n",
      "\n",
      "================================================================================\n",
      "DATA STRUCTURE INSPECTION\n",
      "================================================================================\n",
      "\n",
      "1. FEATURES DATAFRAME\n",
      "   Shape: (203769, 167)\n",
      "   Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]... (showing first 10)\n",
      "   Memory usage: 272.24 MB\n",
      "\n",
      "   First few rows:\n",
      "         0    1         2         3         4        5         6         7    \\\n",
      "0  230425980    1 -0.171469 -0.184668 -1.201369 -0.12197 -0.043875 -0.113002   \n",
      "1    5530458    1 -0.171484 -0.184668 -1.201369 -0.12197 -0.043875 -0.113002   \n",
      "2  232022460    1 -0.172107 -0.184668 -1.201369 -0.12197 -0.043875 -0.113002   \n",
      "\n",
      "        8         9    ...       157       158       159       160       161  \\\n",
      "0 -0.061584 -0.162097  ... -0.562153 -0.600999  1.461330  1.461369  0.018279   \n",
      "1 -0.061584 -0.162112  ...  0.947382  0.673103 -0.979074 -0.978556  0.018279   \n",
      "2 -0.061584 -0.162749  ...  0.670883  0.439728 -0.979074 -0.978556 -0.098889   \n",
      "\n",
      "        162       163       164       165       166  \n",
      "0 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
      "1 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
      "2 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792  \n",
      "\n",
      "[3 rows x 167 columns]\n",
      "\n",
      "2. EDGES DATAFRAME\n",
      "   Shape: (234355, 2)\n",
      "   Column names: ['txId1', 'txId2']\n",
      "\n",
      "   First few rows:\n",
      "       txId1      txId2\n",
      "0  230425980    5530458\n",
      "1  232022460  232438397\n",
      "2  230460314  230459870\n",
      "\n",
      "3. CLASSES DATAFRAME\n",
      "   Shape: (203769, 2)\n",
      "   Column names: ['txId', 'class']\n",
      "\n",
      "   First few rows:\n",
      "        txId    class\n",
      "0  230425980  unknown\n",
      "1    5530458  unknown\n",
      "2  232022460  unknown\n",
      "\n",
      "================================================================================\n",
      "CLASS DISTRIBUTION (THE MOST CRITICAL EDA STEP)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 167 elements, new values have 168 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 105\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# Merge classes with features to get time information\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m \u001b[43mfeatures_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m = [\u001b[33m'\u001b[39m\u001b[33mtxId\u001b[39m\u001b[33m'\u001b[39m] + [\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m167\u001b[39m)] + [\u001b[33m'\u001b[39m\u001b[33mtime_step\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    106\u001b[39m classes_df.columns = [\u001b[33m'\u001b[39m\u001b[33mtxId\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    108\u001b[39m data = features_df.merge(classes_df, on=\u001b[33m'\u001b[39m\u001b[33mtxId\u001b[39m\u001b[33m'\u001b[39m, how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NI\\OneDrive\\Desktop\\Projects\\fraud-detection-gnn\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:6002\u001b[39m, in \u001b[36mNDFrame.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m   6000\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   6001\u001b[39m     \u001b[38;5;28mobject\u001b[39m.\u001b[34m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[32m-> \u001b[39m\u001b[32m6002\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6003\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m   6004\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NI\\OneDrive\\Desktop\\Projects\\fraud-detection-gnn\\.venv\\Lib\\site-packages\\pandas\\_libs\\properties.pyx:69\u001b[39m, in \u001b[36mpandas._libs.properties.AxisProperty.__set__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NI\\OneDrive\\Desktop\\Projects\\fraud-detection-gnn\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:730\u001b[39m, in \u001b[36mNDFrame._set_axis\u001b[39m\u001b[34m(self, axis, labels)\u001b[39m\n\u001b[32m    725\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    726\u001b[39m \u001b[33;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[32m    727\u001b[39m \u001b[33;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[32m    728\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    729\u001b[39m labels = ensure_index(labels)\n\u001b[32m--> \u001b[39m\u001b[32m730\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[38;5;28mself\u001b[39m._clear_item_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NI\\OneDrive\\Desktop\\Projects\\fraud-detection-gnn\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:225\u001b[39m, in \u001b[36mBaseBlockManager.set_axis\u001b[39m\u001b[34m(self, axis, new_labels)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    224\u001b[39m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m     \u001b[38;5;28mself\u001b[39m.axes[axis] = new_labels\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NI\\OneDrive\\Desktop\\Projects\\fraud-detection-gnn\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:70\u001b[39m, in \u001b[36mDataManager._validate_set_axis\u001b[39m\u001b[34m(self, axis, new_labels)\u001b[39m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m new_len != old_len:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     71\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m elements, new \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m elements\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Length mismatch: Expected axis has 167 elements, new values have 168 elements"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FRAUD DETECTION EDA: Understanding the Elliptic Dataset\n",
    "# ============================================================================\n",
    "# \n",
    "# LEARNING GOALS:\n",
    "# 1. Understand data structure (nodes, edges, features, labels)\n",
    "# 2. Identify class imbalance and its implications\n",
    "# 3. Analyze graph topology (degree distribution, connectivity)\n",
    "# 4. Discover temporal patterns (fraud evolves over time)\n",
    "# 5. Inform model design decisions\n",
    "#\n",
    "# INTERVIEW TIP:\n",
    "# \"Before building any model, I always perform thorough EDA to understand\n",
    "# the data generating process, identify potential pitfalls, and validate\n",
    "# modeling assumptions.\"\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# Set project root\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "    \n",
    "from src.data.download import EllipticDataLoader\n",
    "from src.utils.config import get_config\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LOADING ELLIPTIC DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "config = get_config()\n",
    "loader = EllipticDataLoader(config.data.raw_data_dir / \"elliptic\")\n",
    "\n",
    "# Load the three CSV files\n",
    "features_df, edges_df, classes_df = loader.load()\n",
    "\n",
    "print(\"\\n‚úì Data loaded successfully!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: BASIC DATA INSPECTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA STRUCTURE INSPECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. FEATURES DATAFRAME\")\n",
    "print(f\"   Shape: {features_df.shape}\")\n",
    "print(f\"   Columns: {features_df.columns.tolist()[:10]}... (showing first 10)\")\n",
    "print(f\"   Memory usage: {features_df.memory_usage(deep=True).sum() / 1e6:.2f} MB\")\n",
    "print(\"\\n   First few rows:\")\n",
    "print(features_df.head(3))\n",
    "\n",
    "# EXPLANATION:\n",
    "# Column 0: Transaction ID (unique identifier)\n",
    "# Columns 1-94: Local features (transaction-specific attributes)\n",
    "# Columns 95-166: Aggregate features (statistics of connected transactions)\n",
    "# Column 167: Time step (1-49, representing time period)\n",
    "\n",
    "print(\"\\n2. EDGES DATAFRAME\")\n",
    "print(f\"   Shape: {edges_df.shape}\")\n",
    "print(f\"   Column names: {edges_df.columns.tolist()}\")\n",
    "print(\"\\n   First few rows:\")\n",
    "print(edges_df.head(3))\n",
    "\n",
    "# EXPLANATION:\n",
    "# txId1 ‚Üí txId2: Directed edge (money flows from txId1 to txId2)\n",
    "# This represents Bitcoin transactions where outputs of one become inputs of another\n",
    "\n",
    "print(\"\\n3. CLASSES DATAFRAME\")\n",
    "print(f\"   Shape: {classes_df.shape}\")\n",
    "print(f\"   Column names: {classes_df.columns.tolist()}\")\n",
    "print(\"\\n   First few rows:\")\n",
    "print(classes_df.head(3))\n",
    "\n",
    "# EXPLANATION:\n",
    "# txId: Transaction ID\n",
    "# class: \"unknown\", \"1\" (licit), \"2\" (illicit)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: CLASS DISTRIBUTION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLASS DISTRIBUTION (THE MOST CRITICAL EDA STEP)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Merge classes with features to get time information\n",
    "features_df.columns = (\n",
    "    ['txId']\n",
    "    + [f'feature_{i}' for i in range(1, 166)]  # 165 features\n",
    "    + ['time_step']\n",
    ")\n",
    "\n",
    "classes_df.columns = ['txId', 'class']\n",
    "\n",
    "data = features_df.merge(classes_df, on='txId', how='left')\n",
    "\n",
    "# Count classes\n",
    "class_counts = data['class'].value_counts()\n",
    "total = len(data)\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "for cls, count in class_counts.items():\n",
    "    print(f\"  {cls:10s}: {count:6d} ({count/total*100:5.2f}%)\")\n",
    "\n",
    "# CRITICAL INSIGHT:\n",
    "# ~77% unlabeled ‚Üí Semi-supervised learning opportunity\n",
    "# ~2% fraud ‚Üí Extreme class imbalance ‚Üí Need weighted loss or sampling\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  KEY OBSERVATION:\")\n",
    "print(\"   Class imbalance ratio: 1:20 (fraud:licit)\")\n",
    "print(\"   ‚Üí MUST use weighted CrossEntropyLoss or Focal Loss\")\n",
    "print(\"   ‚Üí Evaluation metrics: Precision, Recall, F1 (not accuracy!)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: VISUALIZE CLASS DISTRIBUTION\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart\n",
    "labeled_data = data[data['class'] != 'unknown']\n",
    "class_counts_labeled = labeled_data['class'].value_counts()\n",
    "\n",
    "axes[0].pie(\n",
    "    class_counts_labeled.values, \n",
    "    labels=['Licit', 'Illicit'], \n",
    "    autopct='%1.1f%%',\n",
    "    colors=['#2ecc71', '#e74c3c'],\n",
    "    startangle=90\n",
    ")\n",
    "axes[0].set_title('Labeled Data Distribution\\n(Excluding Unknown)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart (all classes)\n",
    "class_counts.plot(kind='bar', ax=axes[1], color=['#95a5a6', '#2ecc71', '#e74c3c'])\n",
    "axes[1].set_title('Full Dataset Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Class', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_xticklabels(['Unknown', 'Licit', 'Illicit'], rotation=0)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úì Saved: class_distribution.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: TEMPORAL ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEMPORAL ANALYSIS (Fraud Patterns Over Time)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Fraud ratio over time\n",
    "temporal_stats = data.groupby('time_step')['class'].apply(\n",
    "    lambda x: (x == '2').sum() / ((x == '1').sum() + (x == '2').sum())\n",
    ").reset_index()\n",
    "temporal_stats.columns = ['time_step', 'fraud_ratio']\n",
    "\n",
    "print(\"\\nFraud Ratio by Time Step:\")\n",
    "print(temporal_stats.head(10))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(temporal_stats['time_step'], temporal_stats['fraud_ratio'] * 100, \n",
    "         marker='o', linewidth=2, markersize=6, color='#e74c3c')\n",
    "plt.axhline(y=temporal_stats['fraud_ratio'].mean() * 100, \n",
    "            linestyle='--', color='gray', label=f'Mean: {temporal_stats[\"fraud_ratio\"].mean()*100:.2f}%')\n",
    "plt.title('Fraud Ratio Over Time Steps', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time Step', fontsize=12)\n",
    "plt.ylabel('Fraud Ratio (%)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('temporal_fraud_ratio.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úì Saved: temporal_fraud_ratio.png\")\n",
    "\n",
    "# INSIGHT:\n",
    "print(\"\\n‚ö†Ô∏è  KEY OBSERVATION:\")\n",
    "print(\"   Fraud ratio varies over time ‚Üí Temporal features are important!\")\n",
    "print(\"   In production: Use time-based validation (not random split)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: GRAPH STRUCTURE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GRAPH TOPOLOGY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Build NetworkX graph for analysis\n",
    "print(\"\\nBuilding NetworkX graph (this may take ~30 seconds)...\")\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(edges_df.values)\n",
    "\n",
    "print(f\"‚úì Graph built: {G.number_of_nodes():,} nodes, {G.number_of_edges():,} edges\")\n",
    "\n",
    "# Basic graph statistics\n",
    "print(\"\\nGraph Statistics:\")\n",
    "print(f\"  Nodes: {G.number_of_nodes():,}\")\n",
    "print(f\"  Edges: {G.number_of_edges():,}\")\n",
    "print(f\"  Density: {nx.density(G):.6f}\")\n",
    "\n",
    "# Degree distribution\n",
    "in_degrees = dict(G.in_degree())\n",
    "out_degrees = dict(G.out_degree())\n",
    "\n",
    "print(f\"\\nDegree Statistics:\")\n",
    "print(f\"  Avg in-degree:  {np.mean(list(in_degrees.values())):.2f}\")\n",
    "print(f\"  Avg out-degree: {np.mean(list(out_degrees.values())):.2f}\")\n",
    "print(f\"  Max in-degree:  {max(in_degrees.values())}\")\n",
    "print(f\"  Max out-degree: {max(out_degrees.values())}\")\n",
    "\n",
    "# INSIGHT:\n",
    "print(\"\\n‚ö†Ô∏è  KEY OBSERVATION:\")\n",
    "print(\"   Some nodes have VERY high degree ‚Üí Potential hubs (exchanges?)\")\n",
    "print(\"   ‚Üí GraphSAGE's neighbor sampling helps handle this!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: VISUALIZE DEGREE DISTRIBUTION\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# In-degree distribution (log scale)\n",
    "in_deg_counts = Counter(in_degrees.values())\n",
    "degrees, counts = zip(*sorted(in_deg_counts.items()))\n",
    "\n",
    "axes[0].loglog(degrees, counts, 'o-', color='#3498db', alpha=0.7)\n",
    "axes[0].set_title('In-Degree Distribution (Log-Log)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('In-Degree', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Out-degree distribution\n",
    "out_deg_counts = Counter(out_degrees.values())\n",
    "degrees, counts = zip(*sorted(out_deg_counts.items()))\n",
    "\n",
    "axes[1].loglog(degrees, counts, 'o-', color='#e74c3c', alpha=0.7)\n",
    "axes[1].set_title('Out-Degree Distribution (Log-Log)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Out-Degree', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('degree_distribution.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úì Saved: degree_distribution.png\")\n",
    "\n",
    "# INSIGHT:\n",
    "print(\"\\n‚ö†Ô∏è  GRAPH STRUCTURE INSIGHT:\")\n",
    "print(\"   Power-law distribution ‚Üí Real-world network (not random graph)\")\n",
    "print(\"   Few high-degree hubs, many low-degree nodes\")\n",
    "print(\"   ‚Üí This is WHY GNNs work! Structure contains information.\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: ANALYZE FRAUD VS LICIT NODE CHARACTERISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FRAUD vs LICIT: NETWORK CHARACTERISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get degree for labeled nodes\n",
    "node_degrees = pd.DataFrame({\n",
    "    'txId': list(in_degrees.keys()),\n",
    "    'in_degree': list(in_degrees.values()),\n",
    "    'out_degree': list(out_degrees.values())\n",
    "})\n",
    "\n",
    "# Merge with classes\n",
    "node_analysis = node_degrees.merge(classes_df, on='txId', how='inner')\n",
    "node_analysis = node_analysis[node_analysis['class'] != 'unknown']\n",
    "\n",
    "# Compare degrees\n",
    "fraud_degrees = node_analysis[node_analysis['class'] == '2']\n",
    "licit_degrees = node_analysis[node_analysis['class'] == '1']\n",
    "\n",
    "print(\"\\nDegree Statistics by Class:\")\n",
    "print(\"\\nFraud (Illicit) Nodes:\")\n",
    "print(f\"  Avg in-degree:  {fraud_degrees['in_degree'].mean():.2f}\")\n",
    "print(f\"  Avg out-degree: {fraud_degrees['out_degree'].mean():.2f}\")\n",
    "print(f\"  Median in-degree:  {fraud_degrees['in_degree'].median():.2f}\")\n",
    "print(f\"  Median out-degree: {fraud_degrees['out_degree'].median():.2f}\")\n",
    "\n",
    "print(\"\\nLicit (Legitimate) Nodes:\")\n",
    "print(f\"  Avg in-degree:  {licit_degrees['in_degree'].mean():.2f}\")\n",
    "print(f\"  Avg out-degree: {licit_degrees['out_degree'].mean():.2f}\")\n",
    "print(f\"  Median in-degree:  {licit_degrees['in_degree'].median():.2f}\")\n",
    "print(f\"  Median out-degree: {licit_degrees['out_degree'].median():.2f}\")\n",
    "\n",
    "# Statistical test\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "stat, p_value = mannwhitneyu(\n",
    "    fraud_degrees['in_degree'], \n",
    "    licit_degrees['in_degree']\n",
    ")\n",
    "\n",
    "print(f\"\\nMann-Whitney U Test (In-Degree):\")\n",
    "print(f\"  Statistic: {stat:.2f}\")\n",
    "print(f\"  P-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"  ‚úì Fraud and licit nodes have SIGNIFICANTLY different degree distributions!\")\n",
    "else:\n",
    "    print(\"  ‚úó No significant difference found.\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 9: VISUALIZE FEATURE DISTRIBUTIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Select a few features for visualization\n",
    "sample_features = ['feature_1', 'feature_2', 'feature_10', 'feature_50']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "labeled_data_with_features = data[data['class'] != 'unknown']\n",
    "\n",
    "for idx, feature in enumerate(sample_features):\n",
    "    fraud_vals = labeled_data_with_features[labeled_data_with_features['class'] == '2'][feature]\n",
    "    licit_vals = labeled_data_with_features[labeled_data_with_features['class'] == '1'][feature]\n",
    "    \n",
    "    axes[idx].hist(licit_vals, bins=50, alpha=0.6, label='Licit', color='#2ecc71', density=True)\n",
    "    axes[idx].hist(fraud_vals, bins=50, alpha=0.6, label='Fraud', color='#e74c3c', density=True)\n",
    "    axes[idx].set_title(f'{feature} Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Value', fontsize=10)\n",
    "    axes[idx].set_ylabel('Density', fontsize=10)\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_distributions.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úì Saved: feature_distributions.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 10: SUMMARY & MODELING IMPLICATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ EDA SUMMARY & MODELING DECISIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "KEY FINDINGS:\n",
    "‚úì Severe class imbalance (1:20 fraud:licit ratio)\n",
    "‚úì Temporal patterns exist (fraud ratio varies over time)\n",
    "‚úì Power-law degree distribution (real-world network)\n",
    "‚úì Fraud nodes have different network characteristics\n",
    "\n",
    "IMPLICATIONS FOR MODEL DESIGN:\n",
    "1. Loss Function:\n",
    "   ‚Üí Use weighted CrossEntropyLoss (fraud_weight = 10-20)\n",
    "   ‚Üí Alternative: Focal Loss for hard examples\n",
    "\n",
    "2. Evaluation Metrics:\n",
    "   ‚Üí PRIMARY: Precision, Recall, F1-Score, AUC-ROC\n",
    "   ‚Üí AVOID: Accuracy (misleading with 2% fraud)\n",
    "   \n",
    "3. Train/Val/Test Split:\n",
    "   ‚Üí Time-based split (NOT random)\n",
    "   ‚Üí Train on time steps 1-35, Val on 36-42, Test on 43-49\n",
    "   ‚Üí Simulates real deployment (predict future fraud)\n",
    "\n",
    "4. Model Architecture:\n",
    "   ‚Üí GraphSAGE with 2 layers (2-hop neighborhood)\n",
    "   ‚Üí Neighbor sampling (10, 5) to handle high-degree nodes\n",
    "   ‚Üí Dropout 0.5 for regularization\n",
    "\n",
    "5. Feature Engineering:\n",
    "   ‚Üí Keep all 166 features initially\n",
    "   ‚Üí Later: Feature importance analysis\n",
    "   ‚Üí Consider adding: degree features, clustering coefficient\n",
    "\n",
    "6. Semi-Supervised Learning:\n",
    "   ‚Üí 77% unlabeled data ‚Üí Use self-training or pseudo-labeling\n",
    "   ‚Üí Advanced: Label propagation on graph\n",
    "\n",
    "NEXT STEPS:\n",
    "‚Üí Build graph representation (PyTorch Geometric Data object)\n",
    "‚Üí Implement baseline models (Logistic Regression, XGBoost)\n",
    "‚Üí Implement GraphSAGE\n",
    "‚Üí Compare results\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úì EDA COMPLETE - Ready for modeling!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6bc75f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
