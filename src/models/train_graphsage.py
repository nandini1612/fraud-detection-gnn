import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import SAGEConv
from torch_geometric.data import Data
from pathlib import Path
import numpy as np
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_auc_score,
    precision_recall_curve,
    roc_curve,
    f1_score,
)
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import time

from src.utils.config import get_config


class GraphSAGE(nn.Module):
    def __init__(
        self,
        num_features,
        hidden_dim1=128,
        hidden_dim2=64,
        num_classes=2,
        dropout=0.5,
        aggr="mean",
    ):

        super(GraphSAGE, self).__init__()

        # Layer 1: Input â†’ Hidden1 (with mean aggregation)
        self.conv1 = SAGEConv(num_features, hidden_dim1, aggr=aggr)

        # Layer 2: Hidden1 â†’ Hidden2
        self.conv2 = SAGEConv(hidden_dim1, hidden_dim2, aggr=aggr)

        # Output layer: Hidden2 â†’ Classes
        self.lin = nn.Linear(hidden_dim2, num_classes)

        self.dropout = dropout

    def forward(self, x, edge_index):
        """Forward pass"""
        # Layer 1
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=self.dropout, training=self.training)

        # Layer 2
        x = self.conv2(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=self.dropout, training=self.training)

        # Output layer
        x = self.lin(x)

        return F.log_softmax(x, dim=1)


class GraphSAGETrainer:
    def __init__(self, config=None):
        self.config = config or get_config()
        self.model = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.results = {}

    def train(self, data_path: Path = None, epochs=200, lr=0.01, patience=20):
        print("=" * 80)
        print("TRAINING GRAPHSAGE")
        print("=" * 80)

        # Load data
        if data_path is None:
            data_path = self.config.data.processed_data_dir / "fraud_graph.pt"

        print(f"\nðŸ“‚ Loading data from {data_path}...")
        data = torch.load(data_path)

        print(f"   âœ“ Loaded: {data.num_nodes:,} nodes, {data.num_edges:,} edges")
        print(f"   âœ“ Device: {self.device}")

        # Move data to device
        data = data.to(self.device)

        # Count fraud in each split
        train_fraud = (data.y[data.train_mask] == 1).sum().item()
        val_fraud = (data.y[data.val_mask] == 1).sum().item()
        test_fraud = (data.y[data.test_mask] == 1).sum().item()

        print(f"\nðŸ“Š Dataset splits:")
        print(f"   Train: {data.train_mask.sum():,} samples ({train_fraud:,} fraud)")
        print(f"   Val:   {data.val_mask.sum():,} samples ({val_fraud:,} fraud)")
        print(f"   Test:  {data.test_mask.sum():,} samples ({test_fraud:,} fraud)")

        print(f"\nðŸ”„ Training mode: Full-batch (processing entire graph)")
        print(
            f"   Note: For large-scale production, use neighbor sampling with pyg-lib"
        )

        # Calculate class weights
        train_labels = data.y[data.train_mask]
        num_legitimate = (train_labels == 0).sum().item()
        num_fraud = (train_labels == 1).sum().item()

        weight_legitimate = len(train_labels) / (2 * num_legitimate)
        weight_fraud = len(train_labels) / (2 * num_fraud)
        class_weights = torch.tensor([weight_legitimate, weight_fraud]).to(self.device)

        print(
            f"\nâš–ï¸  Class weights: Legitimate={weight_legitimate:.4f}, Fraud={weight_fraud:.4f}"
        )

        # Initialize model
        print(f"\nðŸ”§ Initializing GraphSAGE...")
        print(f"   â€¢ Architecture: {data.num_node_features} â†’ 128 â†’ 64 â†’ 2")
        print(f"   â€¢ Aggregation: Mean")
        print(f"   â€¢ Dropout: 0.5")
        print(f"   â€¢ Optimizer: Adam (lr={lr})")

        self.model = GraphSAGE(
            num_features=data.num_node_features,
            hidden_dim1=128,
            hidden_dim2=64,
            num_classes=2,
            dropout=0.5,
            aggr="mean",
        ).to(self.device)

        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=5e-4)
        criterion = nn.NLLLoss(weight=class_weights)

        # Training loop
        print(f"\nðŸš€ Training for up to {epochs} epochs...")
        print(f"   Early stopping patience: {patience} epochs")

        best_val_f1 = 0
        patience_counter = 0
        train_losses = []
        val_f1_scores = []

        start_time = time.time()

        for epoch in tqdm(range(epochs), desc="Training"):
            # Train
            self.model.train()
            optimizer.zero_grad()

            # Forward pass on entire graph
            out = self.model(data.x, data.edge_index)

            # Compute loss only on training nodes
            loss = criterion(out[data.train_mask], data.y[data.train_mask])

            loss.backward()
            optimizer.step()

            train_losses.append(loss.item())

            # Evaluate on validation set
            self.model.eval()
            with torch.no_grad():
                out = self.model(data.x, data.edge_index)
                pred = out.argmax(dim=1)

                val_pred = pred[data.val_mask].cpu().numpy()
                val_true = data.y[data.val_mask].cpu().numpy()

                val_f1 = f1_score(val_true, val_pred, average="binary", zero_division=0)
                val_f1_scores.append(val_f1)

            # Early stopping check
            if val_f1 > best_val_f1:
                best_val_f1 = val_f1
                patience_counter = 0
                # Save best model
                best_model_state = self.model.state_dict().copy()
            else:
                patience_counter += 1

            # Print progress every 20 epochs
            if (epoch + 1) % 20 == 0:
                elapsed = time.time() - start_time
                print(
                    f"\n   Epoch {epoch + 1:3d}/{epochs}: Loss={loss.item():.4f}, Val F1={val_f1:.4f}, Time={elapsed:.1f}s"
                )

            # Early stopping
            if patience_counter >= patience:
                print(
                    f"\n   âš ï¸  Early stopping at epoch {epoch + 1} (no improvement for {patience} epochs)"
                )
                break

        # Load best model
        self.model.load_state_dict(best_model_state)

        total_time = time.time() - start_time
        print(f"\n   âœ“ Training complete!")
        print(f"   âœ“ Best Val F1: {best_val_f1:.4f}")
        print(f"   âœ“ Total time: {total_time:.1f}s ({total_time / 60:.1f} minutes)")

        # Full evaluation on all splits
        print(f"\nðŸ“ˆ Final Evaluation...")

        self.model.eval()
        with torch.no_grad():
            out = self.model(data.x, data.edge_index)
            pred = out.argmax(dim=1)
            proba = torch.exp(out)[:, 1]

        self.results["train"] = self._evaluate_predictions(
            data.y[data.train_mask].cpu().numpy(),
            pred[data.train_mask].cpu().numpy(),
            proba[data.train_mask].cpu().numpy(),
            "Train",
        )

        self.results["val"] = self._evaluate_predictions(
            data.y[data.val_mask].cpu().numpy(),
            pred[data.val_mask].cpu().numpy(),
            proba[data.val_mask].cpu().numpy(),
            "Validation",
        )

        self.results["test"] = self._evaluate_predictions(
            data.y[data.test_mask].cpu().numpy(),
            pred[data.test_mask].cpu().numpy(),
            proba[data.test_mask].cpu().numpy(),
            "Test",
        )

        # Print summary
        self._print_summary()

        # Plot results
        self._plot_results()

        # Plot training curves
        self._plot_training_curves(train_losses, val_f1_scores)

        # Save model
        self._save_model()

        return self.results

    def _evaluate_predictions(self, y_true, y_pred, y_proba, split_name):
        """Full evaluation with all metrics"""
        report = classification_report(
            y_true, y_pred, output_dict=True, zero_division=0
        )
        auc = roc_auc_score(y_true, y_proba)
        cm = confusion_matrix(y_true, y_pred)

        results = {
            "precision": report["1"]["precision"],
            "recall": report["1"]["recall"],
            "f1": report["1"]["f1-score"],
            "auc": auc,
            "confusion_matrix": cm,
            "y_true": y_true,
            "y_pred": y_pred,
            "y_proba": y_proba,
        }

        return results

    def _print_summary(self):
        """Print results summary"""
        print("\n" + "=" * 80)
        print("RESULTS SUMMARY")
        print("=" * 80)

        for split_name in ["train", "val", "test"]:
            results = self.results[split_name]
            print(f"\n{split_name.upper()} SET:")
            print(f"   Precision: {results['precision']:.4f}")
            print(f"   Recall:    {results['recall']:.4f}")
            print(f"   F1-Score:  {results['f1']:.4f}")
            print(f"   AUC-ROC:   {results['auc']:.4f}")

            # Confusion matrix
            tn, fp, fn, tp = results["confusion_matrix"].ravel()
            print(f"\n   Confusion Matrix:")
            print(f"   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            print(f"   â”‚             â”‚ Pred Neg â”‚ Pred Pos â”‚")
            print(f"   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
            print(f"   â”‚ Actual Neg  â”‚ {tn:8d} â”‚ {fp:8d} â”‚")
            print(f"   â”‚ Actual Pos  â”‚ {fn:8d} â”‚ {tp:8d} â”‚")
            print(f"   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

        print("\n" + "=" * 80)
        print("MODEL COMPARISON")
        print("=" * 80)
        print("\nðŸ“Š Test Set F1 Scores:")
        print("   â€¢ Logistic Regression: 0.098")
        print("   â€¢ XGBoost:            0.035")
        print("   â€¢ Simple GCN:         0.045")
        print(f"   â€¢ GraphSAGE:          {self.results['test']['f1']:.3f}")

        # Determine if we improved
        best_baseline = max(0.098, 0.035, 0.045)
        improvement = (self.results["test"]["f1"] - best_baseline) / best_baseline * 100

        if self.results["test"]["f1"] > best_baseline:
            print(f"\nGraphSAGE beats best baseline by {improvement:.1f}%!")
        else:
            print(f"\nGraphSAGE didn't beat best baseline ({improvement:.1f}%)")

        print("=" * 80)

    def _plot_results(self):
        """Create visualizations"""
        results = self.results["test"]

        fig, axes = plt.subplots(1, 3, figsize=(18, 5))

        # 1. Confusion Matrix
        cm = results["confusion_matrix"]
        sns.heatmap(
            cm,
            annot=True,
            fmt="d",
            cmap="RdPu",
            ax=axes[0],
            xticklabels=["Legitimate", "Fraud"],
            yticklabels=["Legitimate", "Fraud"],
        )
        axes[0].set_title("Confusion Matrix (Test Set)", fontsize=14, fontweight="bold")
        axes[0].set_ylabel("True Label")
        axes[0].set_xlabel("Predicted Label")

        # 2. ROC Curve
        fpr, tpr, _ = roc_curve(results["y_true"], results["y_proba"])
        axes[1].plot(
            fpr, tpr, linewidth=2, label=f"AUC = {results['auc']:.4f}", color="darkred"
        )
        axes[1].plot([0, 1], [0, 1], "k--", linewidth=1, label="Random")
        axes[1].set_xlabel("False Positive Rate")
        axes[1].set_ylabel("True Positive Rate")
        axes[1].set_title("ROC Curve (Test Set)", fontsize=14, fontweight="bold")
        axes[1].legend()
        axes[1].grid(alpha=0.3)

        # 3. Precision-Recall Curve
        precision, recall, _ = precision_recall_curve(
            results["y_true"], results["y_proba"]
        )
        axes[2].plot(recall, precision, linewidth=2, color="darkred")
        axes[2].set_xlabel("Recall")
        axes[2].set_ylabel("Precision")
        axes[2].set_title(
            "Precision-Recall Curve (Test Set)", fontsize=14, fontweight="bold"
        )
        axes[2].grid(alpha=0.3)

        # Add baseline
        fraud_rate = (results["y_true"] == 1).mean()
        axes[2].axhline(
            fraud_rate,
            color="red",
            linestyle="--",
            linewidth=1,
            label=f"Random (P={fraud_rate:.3f})",
        )
        axes[2].legend()

        plt.tight_layout()

        # Save
        output_dir = Path("outputs")
        output_dir.mkdir(parents=True, exist_ok=True)
        save_path = output_dir / "graphsage_results.png"
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        print(f"\nâœ“ Plots saved to: {save_path}")

        plt.show()

    def _plot_training_curves(self, train_losses, val_f1_scores):
        """Plot training curves"""
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        # Loss curve
        axes[0].plot(train_losses, linewidth=2, color="darkred")
        axes[0].set_xlabel("Epoch")
        axes[0].set_ylabel("Training Loss")
        axes[0].set_title("Training Loss Curve", fontsize=14, fontweight="bold")
        axes[0].grid(alpha=0.3)

        # F1 curve
        axes[1].plot(val_f1_scores, linewidth=2, color="darkorange")
        axes[1].set_xlabel("Epoch")
        axes[1].set_ylabel("Validation F1 Score")
        axes[1].set_title("Validation F1 Curve", fontsize=14, fontweight="bold")
        axes[1].grid(alpha=0.3)

        plt.tight_layout()

        # Save
        output_dir = Path("outputs")
        save_path = output_dir / "graphsage_training_curves.png"
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        print(f"âœ“ Training curves saved to: {save_path}")

        plt.show()

    def _save_model(self):
        """Save trained model"""
        output_dir = Path("outputs/models")
        output_dir.mkdir(parents=True, exist_ok=True)

        save_path = output_dir / "graphsage_best.pt"
        torch.save(
            {
                "model_state_dict": self.model.state_dict(),
                "results": self.results,
            },
            save_path,
        )

        print(f"\nâœ“ Model saved to: {save_path}")


def main():
    """Train GraphSAGE model"""
    config = get_config()
    trainer = GraphSAGETrainer(config)

    # Train
    results = trainer.train(epochs=200, lr=0.01, patience=20)

    print("\nGraphSAGE training complete!")
    print("\nNext steps:")
    print("   â€¢ Analyze results vs baselines")
    print("   â€¢ Create final comparison table")
    print("   â€¢ Prepare interview talking points")


if __name__ == "__main__":
    main()
